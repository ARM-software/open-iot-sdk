# Copyright (c) 2021-2022 Arm Limited and Contributors. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

include:
  - project: '${OPEN_IOT_SDK_BASE_GROUP}/tools/developer-tools'
    ref: cc5fd9dcb0c9d72fd2ce15e843d5e28b543bde86
    file:
      - '/templates/pipeline-baseline-sdk.yml'
      - '/templates/sync-public/pipeline-sync-public.yml'
      - '/templates/autobot/pipeline-autobot.yml'

variables:
  DOCKER_TAG: "$CI_COMMIT_REF_SLUG"
  # Default DOCKER_TAG, set this accordingly to trigger against
  # another AVH version
  AVH_DOCKER_TAG: "11.18.29"
  AVH_INSTANCE_NAME_PREFIX: "iot-os-m-avh-testing-"
  # Default AWS_AMI_VERSION, set this accordingly to trigger against
  # another AMI VERSION
  AWS_AMI_VERSION: "1.3.0"
  SYNC_DESTINATION : 'https://${GITLAB_USER_ID}:${PUBLIC_SDK_TOKEN}@git.gitlab.arm.com/iot/open-iot-sdk/examples/total-solutions.git'

stages:
  - autobot
  - quality-check
  - build
  - test
  - cleanup
  - sync-public

workflow:
  rules:
    - if: $CI_MERGE_REQUEST_ID
    - if: $CI_COMMIT_REF_NAME =~ /^release-.*/
    - if: $CI_PIPELINE_SOURCE == "web"
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# This job will run only if AUTO_UPDATE_WORKFLOW is set
# Normally this is expected to set in a scheduled pipeline
# in this repository
autobot:
  stage: autobot
  image: ${OPEN_IOT_SDK_DOCKER_REGISTRY}/sanity:v1
  variables:
    AUTO_MERGE: "true"
  tags:
    - iotmsw-amd64
  extends:
    - .autobot
  rules:
    - if: $AUTO_UPDATE_WORKFLOW == "true"

.ami-test-base:
  stage: build
  image: "${OPEN_IOT_SDK_PRIVATE_DOCKER_REGISTRY}/avh:${AVH_DOCKER_TAG}"
  tags:
    - docker
  variables:
    AWS_S3_BUCKET_NAME: avh-test-bucket
    AWS_SUBNET_ID: subnet-0e3d516f4c179f329
    AWS_SECURITY_GROUP_ID: sg-00647a48ceacf3f50
    AWS_IAM_PROFILE: Proj-Jenkins-Perms-Profile
    AWS_DEFAULT_REGION: eu-west-1
    BUILD_PATH: build
    CREDENTIALS_PATH: credentials
  script:
    - pip install arm-avhclient
    - export PATH=$HOME/.local/bin:$PATH
    # generate device credentials for ota test
    - ./ci/generate_credentials.sh -p $CREDENTIALS_PATH
    # We need to pass following environment variables to
    # EC2 instance running AVH AMI. Move the environmental variable
    # to a temporary file and this file will be referenced by avh.yml
    - |
      echo """
        export IOT_AWS_REGION='"$IOT_AWS_REGION"'
        export IOT_OTA_ROLE_NAME='"$IOT_OTA_ROLE_NAME"'
        export IOT_OTA_CERT_ID='"$IOT_OTA_CERT_ID"'
        export IOT_OTA_ENDPOINT='"$IOT_OTA_ENDPOINT"'
        export IOT_OTA_CLIENT_CERT='"$IOT_OTA_CLIENT_CERT"'
        export IOT_OTA_CLIENT_PRIV='"$IOT_OTA_CLIENT_PRIV"'
        export IOT_OTA_CLIENT_PUB='"$IOT_OTA_CLIENT_PUB"'
        export TEST='"$TEST"'
        export BUILD_PATH='"$BUILD_PATH"'
        export CREDENTIALS_PATH='"$CREDENTIALS_PATH"'
        export AVH='"$AVH"'
        export TARGET='"$TARGET"'
        export RTOS='"$RTOS"'
        export APPLICATIONS_TO_BUILD='"$APPLICATIONS_TO_BUILD"'
        export PYTEST_SELECTION='"$PYTEST_SELECTION"'
        export ENDPOINT='"$ENDPOINT"'
      """ > ci/env.sh
    - >
      ./developer-tools/utils/cloud_helper/az.sh
      --template-type iot
      --out-file "$CREDENTIALS_PATH"/iothub_credentials.h
    - >
      ./developer-tools/utils/cloud_helper/az.sh
      --template-type nx
      --out-file "$CREDENTIALS_PATH"/azure_iot_credentials.h
    - export AWS_INSTANCE_NAME="${AVH_INSTANCE_NAME_PREFIX}${CI_JOB_ID}"
    - avhclient -b aws execute --specfile ci/avh.yml
  artifacts:
    expire_in: 1 week
    when: always
    paths:
      - report*.xml
    reports:
      junit: report*.xml
  rules:
    - if: $RUN_AMI_WORKFLOW == "true"

ami-test-aws:
  extends: .ami-test-base
  parallel:
    matrix:
      - TARGET: Corstone-300
        RTOS: [FREERTOS, RTX]
        AVH: VHT_Corstone_SSE-300_Ethos-U55
        APPLICATIONS_TO_BUILD: blinky, keyword, speech
        PYTEST_SELECTION: examples/blinky/tests,examples/keyword/tests/test_ml.py,examples/keyword/tests/test_ota.py,examples/speech/tests/test_ml.py,examples/speech/tests/test_ota.py
        ENDPOINT: [AWS]
      - TARGET: Corstone-310
        RTOS: [FREERTOS, RTX]
        AVH: VHT_Corstone_SSE-310
        APPLICATIONS_TO_BUILD: blinky, keyword, speech
        PYTEST_SELECTION: examples/blinky/tests,examples/keyword/tests/test_ml.py,examples/keyword/tests/test_ota.py,examples/speech/tests/test_ml.py,examples/speech/tests/test_ota.py
        ENDPOINT: [AWS]

ami-test-mlia:
  extends: .ami-test-base
  parallel:
    matrix:
      # Though most of the argument is unused, pass it to avh.yml
      # to make the script common for other tests.
      - TARGET: Corstone-300
        RTOS: [FREERTOS]
        AVH: VHT_Corstone_SSE-300_Ethos-U55
        APPLICATIONS_TO_BUILD: mlia
        PYTEST_SELECTION: "mlia/tests/test_ats_mlia.py"
        ENDPOINT: [AWS]

ami-test-azure:
  extends: .ami-test-base
  parallel:
    matrix:
      - TARGET: Corstone-300
        RTOS: [FREERTOS, RTX, THREADX]
        AVH: VHT_Corstone_SSE-300_Ethos-U55
        APPLICATIONS_TO_BUILD: blinky, keyword, speech
        PYTEST_SELECTION: "examples/blinky/tests,examples/keyword/tests/test_ml.py,examples/keyword/tests/test_azure.py ,examples/speech/tests/test_ml.py,examples/speech/tests/test_azure.py"
        ENDPOINT: [AZURE]
      - TARGET: Corstone-310
        RTOS: [FREERTOS, RTX, THREADX]
        AVH: VHT_Corstone_SSE-310
        APPLICATIONS_TO_BUILD: blinky, keyword, speech
        PYTEST_SELECTION: "examples/blinky/tests,examples/keyword/tests/test_ml.py,examples/keyword/tests/test_azure.py,examples/speech/tests/test_ml.py,examples/speech/tests/test_azure.py"
        ENDPOINT: [AZURE]

# This base job load the right docker image and sets some default variables
.base_job:
  extends: .base-job-rules
  tags:
    - iotmsw-amd64
  image: "${OPEN_IOT_SDK_PRIVATE_DOCKER_REGISTRY}/avh:${AVH_DOCKER_TAG}"
  variables:
    PYTHONUNBUFFERED: 1
    BUILD_FOLDER: build-${TARGET}-${RTOS}-${ENDPOINT}


# The test job extends .basejob. It add rules to map targets to AVH binaries,
# require the application to be built and retrieve the artifacts.
.test_job:
  stage: test
  extends: .base_job
  needs:
    - job: build-applications
      artifacts: true
  before_script:
    - |
      if [ $TARGET == "Corstone-300" ];then
        AVH=/opt/VHT/VHT_Corstone_SSE-300_Ethos-U55
      fi
    - |
      if [ $TARGET == "Corstone-310" ];then
        AVH=/opt/VHT/VHT_Corstone_SSE-310
      fi


# Those fragments contain base variables required by pipelines for AWS and Azure.
# They can be used to set matrix parameters and extended using << : .anchor syntax
.pipeline_config_aws: &pipeline_config_aws
  TARGET: [Corstone-300, Corstone-310]
  RTOS: [FREERTOS, RTX]
  ENDPOINT: [AWS]

.pipeline_config_azure: &pipeline_config_azure
  TARGET: [Corstone-300, Corstone-310]
  RTOS: [THREADX, RTX]
  ENDPOINT: [AZURE]

.pipeline_config_azure_netxduo: &pipeline_config_azure_netxduo
  TARGET: [Corstone-300, Corstone-310]
  RTOS: [THREADX]
  ENDPOINT: [AZURE_NETXDUO]

# Build all the applications which later are tested. Build of the various binaries
# is described in ./ci/build_examples.sh
build-applications:
  stage: build
  extends: .base_job
  script:
    - env
    - ./ci/generate_credentials.sh -p "$BUILD_FOLDER"_credentials_keyword
    - ./ci/generate_credentials.sh -p "$BUILD_FOLDER"_credentials_speech
    - >
      ./developer-tools/utils/cloud_helper/az.sh
      --template-type iot
      --out-file "$BUILD_FOLDER"_credentials_keyword/iothub_credentials.h
    - >
      ./developer-tools/utils/cloud_helper/az.sh
      --template-type iot
      --out-file "$BUILD_FOLDER"_credentials_speech/iothub_credentials.h
    - >
      ./developer-tools/utils/cloud_helper/az.sh
      --template-type nx
      --out-file "$BUILD_FOLDER"_credentials_keyword/azure_iot_credentials.h
    - >
      ./developer-tools/utils/cloud_helper/az.sh
      --template-type nx
      --out-file "$BUILD_FOLDER"_credentials_speech/azure_iot_credentials.h
    - ./ci/build_examples.sh
  artifacts:
    paths:
      # examples
      - ${BUILD_FOLDER}/bootloader/bl2.axf
      - ${BUILD_FOLDER}/secure_partition/tfm_s_signed.bin
      - ${BUILD_FOLDER}/examples/blinky/blinky_signed.bin
      - ${BUILD_FOLDER}/examples/keyword/keyword_signed.bin
      - ${BUILD_FOLDER}/examples/keyword/keyword_signed_update.bin
      - ${BUILD_FOLDER}/examples/keyword/update-signature.txt
      - ${BUILD_FOLDER}/examples/speech/speech_signed.bin
      - ${BUILD_FOLDER}/examples/speech/speech_signed_update.bin
      - ${BUILD_FOLDER}/examples/speech/update-signature.txt
      # keyword cloud
      - ${BUILD_FOLDER}_cloud_keyword/bootloader/bl2.axf
      - ${BUILD_FOLDER}_cloud_keyword/secure_partition/tfm_s_signed.bin
      - ${BUILD_FOLDER}_cloud_keyword/examples/keyword/keyword_signed.bin
      - ${BUILD_FOLDER}_cloud_keyword/examples/keyword/keyword_signed_update.bin
      - ${BUILD_FOLDER}_cloud_keyword/examples/keyword/update-signature.txt
      # speech cloud
      - ${BUILD_FOLDER}_cloud_speech/bootloader/bl2.axf
      - ${BUILD_FOLDER}_cloud_speech/secure_partition/tfm_s_signed.bin
      - ${BUILD_FOLDER}_cloud_speech/examples/speech/speech_signed.bin
      - ${BUILD_FOLDER}_cloud_speech/examples/speech/speech_signed_update.bin
      - ${BUILD_FOLDER}_cloud_speech/examples/speech/update-signature.txt
      - ${BUILD_FOLDER}_credentials_keyword/*
      - ${BUILD_FOLDER}_credentials_speech/*
      - credentials/*
    expire_in: 1 week
  parallel:
    matrix:
      - *pipeline_config_aws
      - *pipeline_config_azure
      - *pipeline_config_azure_netxduo

# Test the blinky and ML part of the KWS application
test-application:
  extends: .test_job
  script:
    - env
    - echo $AVH
    - pytest -s ${TEST_PATH} --build-path ${BUILD_FOLDER} --avh ${AVH}
  parallel:
    matrix:
      -
        << : *pipeline_config_aws
        TEST_PATH: [examples/blinky/tests, examples/keyword/tests/test_ml.py, examples/speech/tests/test_ml.py]
      -
        << : *pipeline_config_azure
        TEST_PATH: [examples/blinky/tests, examples/keyword/tests/test_ml.py, examples/speech/tests/test_ml.py]
      -
        << : *pipeline_config_azure_netxduo
        TEST_PATH: [examples/blinky/tests, examples/keyword/tests/test_ml.py, examples/speech/tests/test_ml.py]

# Test connection to the AWS cloud
test-ota-aws:
  extends: .test_job
  script:
    - env
    - . ./ci/assume_role.sh
    - pytest -s examples/${APP}/tests/test_ota.py --build-path "$BUILD_FOLDER"_cloud_${APP} --avh $AVH --credentials-path "$BUILD_FOLDER"_credentials_${APP}
  parallel:
    matrix:
      -
        << : *pipeline_config_aws
        APP: [keyword, speech]

# Test connection to the azure cloud
test-ml-azure:
  extends: .test_job
  script:
    - env
    - pytest -s examples/${APP}/tests/test_azure.py --build-path "$BUILD_FOLDER"_cloud_${APP} --avh $AVH
  parallel:
    matrix:
      -
        << : *pipeline_config_azure
        APP: [keyword, speech]
      -
        << : *pipeline_config_azure_netxduo
        APP: [keyword, speech]

test-mlia:
  extends: .base-job-rules
  stage: test
  tags:
    - iotmsw-amd64
  image: "${OPEN_IOT_SDK_PRIVATE_DOCKER_REGISTRY}/avh:${AVH_DOCKER_TAG}"
  script:
    - env
    - ls /opt/VHT/
    - ./ats.sh build mlia --clean
    - pytest mlia/tests/test_ats_mlia.py


aws-cleanup:
  stage: cleanup
  tags:
    - iotmsw-amd64
  image: "${OPEN_IOT_SDK_PRIVATE_DOCKER_REGISTRY}/avh:${AVH_DOCKER_TAG}"
  rules:
    - if: $GARBAGE_COLLECT == "true"
  script:
    - . ./ci/assume_role.sh
    - python -u ./ci/aws_cleanup.py

avh-cleanup:
  stage: cleanup
  image: "${OPEN_IOT_SDK_PRIVATE_DOCKER_REGISTRY}/sanity:v1"
  tags:
    - docker

  script:
    - python ci/cleanup_avh_instances.py "${AVH_INSTANCE_NAME_PREFIX}"
  rules:
    - if: $GARBAGE_COLLECT == "true"


# This is triggered when a commit is added to the DEFAULT(often `main`) branch in internal GitLab
# This job will push DEFAULT branch changes to the public GitLab
push-public:
  extends: .push-public
  stage: sync-public

# This job is triggered by scheduled pipeline of this repository running in internal GitLab.
# This job will pull changes of the branch which is set to run the scheduled pipeline (often `main` branch).
pull-public:
  extends: .pull-public
  stage: sync-public
